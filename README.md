# Data-Structures-Implementation 

These are my implementations of data structures in Java from scratch. I will do it on purpose to implement most of the same functions and features as the Java [Collections](https://docs.oracle.com/javase/7/docs/api/java/util/Collections.html) library, but my own way. Many of the structures aren't even integrated in Java anyways. The purpose of this project is to understand how these data structures work to be able to use them efficiently later on. At the same time, I'll be doing a study of the complexity of all the data structure's features. Project started on April 28th, 2020. 

Up to date implemented data structures:
* *__LinkedList__*: File: *BasicLinkedList.java*. This is a basic [LinkedList](https://docs.oracle.com/javase/7/docs/api/java/util/LinkedList.html) data structure with a root node and every node has a pointer to the next node in the list. I implemented a simple one with only a reference to the root node. However, there are better more optimized ways of storing and using a linked list. More info in the first few lines of the *BasicLinkedList.java* file in the *dataStructures.linkedLists* package. Along with this data structure, I implemented a divide and conquer sorting algorithm, aka [MergeSort](https://en.wikipedia.org/wiki/Merge_sort). This is the best way to sort a linked list since [QuickSort](https://en.wikipedia.org/wiki/Quicksort) is slow due to random access' not being efficient with linked lists.

* *__DoublyLinkedList__*: File: *DoublyLinkedList.java*. This data structure is a [doubly linked list](https://en.wikipedia.org/wiki/Doubly_linked_list) very similar to the single linked list above except that it contains a reference to the last (tail) node in addition to the root node. Also, every node has a reference to each of the 2 surrounding nodes. The main advantages over a singly linked list is now we can access the first and last nodes, the root and tail nodes, in constant time. Appending and prepending are both done in constant time too. Inserting, removing and getting values with an index are also slightly quicker. The disadvantage is you store double the amount of pointers to nodes than in singly linked lists. A doubly linked list can be used as [Queues](https://docs.oracle.com/javase/7/docs/api/java/util/Queue.html) and [Deques](https://docs.oracle.com/javase/7/docs/api/java/util/Deque.html).

* *__ArrayList__*: File: *BasicArrayList.java*. This is a basic *dynamic* array data structure. It resembles the [ArrayList](https://docs.oracle.com/javase/8/docs/api/java/util/ArrayList.html) collection implemented in Java 2 and the [Vector](https://en.cppreference.com/w/cpp/container/vector) class in C++. The implemented search algorithm is [Binary Search](https://en.wikipedia.org/wiki/Binary_search_algorithm) and the implemented sort algorithms are [InsertionSort](https://en.wikipedia.org/wiki/Insertion_sort) for small arrays under 64 elements (because it's quicker), Quicksort for arrays between 64 and 256 in size and MergeSort for bigger arrays.

* *__Stack__*: File: *BasicStack.java*. This is Stack class. It extends the *BasicArrayList* class and adds the needed *push()*, *pop()*, and *peek()* functions. It's similar to the [Stack](https://docs.oracle.com/javase/7/docs/api/java/util/Stack.html) class in Java collections. 

* *__BinaryTree__*: File: *BinaryTree.java*. This is an abstract [Binary Tree](https://www.geeksforgeeks.org/binary-tree-set-1-introduction/) class. Two classes extend this class, *LevelBinaryTree.java* and *BinarySearchTree.java*. The Level Binary Tree is a binary tree ordered by levels, every new inserted element is added to the first available spot, hence the "level" identifier. To insert and delete elements in this tree, the goto algorithm is [Breadth First Search](https://en.wikipedia.org/wiki/Breadth-first_search). The same algorithm is used to check if a tree contains an element. The [Binary Search Tree](https://www.geeksforgeeks.org/binary-search-tree-data-structure/) is a tree where every left node is smaller than it's parent node and every right node is bigger than its parent node. This order is called inorder. Since this tree is "sorted" in a way, we can take advantage of this property and make super efficient algorithms for searching, adding and deleting. This algorithm looks like a mix of Binary Search and [Depth First Search](https://en.wikipedia.org/wiki/Depth-first_search).

* *__HashSet__* & *__HashTable__*: Files: *HashTable.java* & *HashSet.java*. These are classes that represent the functionality of [Hash Tables](https://docs.oracle.com/javase/8/docs/api/java/util/Hashtable.html) and [Hash Sets](https://docs.oracle.com/javase/7/docs/api/java/util/HashSet.html). A Set is a unordered and unindexed collection. A Hash Table or Dictionary is a unordered collection of key-value pairs. Look up, adding, getting, setting and removing are done in constant time with these data structures.

* *__Heap__*: File: *Heap.java*. In this file, there a 2 declared static classes: MaxHeap and MinHeap. A [Heap](https://en.wikipedia.org/wiki/Heap_(data_structure)) is a tree-based data structure that holds a specific ordering property. A Min Heap has a property that every parent node is smaller or equal to the children node. So the root node is the smallest. A Max Heap has the property that every parent is bigger or equal to the children nodes. So the root node ia the biggest. 

What is to come next?
* [Graphs](https://www.geeksforgeeks.org/graph-data-structure-and-algorithms/)
* [Tries](https://en.wikipedia.org/wiki/Trie)

Every sub-package has a tester class where I test every function and feature. Those classes are very messy. However, they are not meant to be neat, they are just for testing purposes. Also, every function has it's run-time and space complexity written next to the declaration.

More in depth explanations on my website shortly after every implementation. And perhaps even a YouTube video if it's really important to make one.  